{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential, regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import random as r\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import os\n",
    "from itertools import *\n",
    "\n",
    "train_dir = 'asl_alphabet_train'\n",
    "test_dir = 'asl_alphabet_test'\n",
    "data_names = 'A B C D E F G H I J K L M N O P Q R S T U V W X Y Z space del nothing'\n",
    "data_dict = dict([(j, i) for i, j in zip(range(len(data_names.split(' '))), data_names.split(' '))])\n",
    "data_inverse = dict([(i, j) for i, j in zip(range(len(data_names.split(' '))), data_names.split(' '))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data From: R U I N G Z T S A F O H del nothing space M J C D V Q X E B K L Y P W \n",
      "All data loaded!\n",
      "82650 images loaded for training; shape = (82650, 64, 64, 3)\n",
      "4350 images loaded for testing; shape = (4350, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    images = []\n",
    "    labels = []\n",
    "    print('Loading Data From: ', end='')\n",
    "    for fo in os.listdir(train_dir):\n",
    "        if fo == '.DS_Store': continue\n",
    "        print(fo, end=' ')\n",
    "        for img in os.listdir(train_dir + '/' + fo):\n",
    "            if img == '.DS_Store': continue\n",
    "            img_data = cv2.resize(cv2.imread(train_dir + '/' + fo + '/' + img), (64, 64))\n",
    "            if fo in data_dict:\n",
    "                images.append(img_data)\n",
    "                labels.append(data_dict[fo])\n",
    "                    \n",
    "    print('\\nAll data loaded!')\n",
    "                \n",
    "    images= np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    \n",
    "    labels = keras.utils.to_categorical(labels)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
    "        \n",
    "    print('%d images loaded for training; shape = %s' % (len(X_train), str(X_train.shape)))\n",
    "    print('%d images loaded for testing; shape = %s' % (len(X_test), str(X_test.shape)))\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 21, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                14877     \n",
      "=================================================================\n",
      "Total params: 942,557\n",
      "Trainable params: 942,045\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    m = Sequential()\n",
    "    m.add(Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))\n",
    "    m.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    m.add(MaxPool2D(pool_size = [3,3]))\n",
    "    m.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    m.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    m.add(MaxPool2D(pool_size = [3,3]))\n",
    "    m.add(Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    m.add(Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
    "    m.add(MaxPool2D(pool_size = [3,3]))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Flatten())\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(512, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\n",
    "    m.add(Dense(29, activation = 'softmax'))\n",
    "    m.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n",
    "    m.summary()\n",
    "    return m\n",
    "\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74385 samples, validate on 8265 samples\n",
      "Epoch 1/1\n",
      "74385/74385 [==============================] - 737s 10ms/step - loss: 0.2712 - acc: 0.9645 - val_loss: 0.4081 - val_acc: 0.8992\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    h = model.fit(X_train, Y_train, batch_size = 64, epochs = 1, validation_split = 0.1)\n",
    "    return h\n",
    "\n",
    "h = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img in os.listdir(test_dir):\n",
    "        tmp = cv2.imread(test_dir + '/' + img)\n",
    "        tmp = cv2.resize(tmp, (64, 64))\n",
    "        images.append(tmp)\n",
    "        labels.append(data_dict[img.split('_')[0]])\n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    return images, labels\n",
    "\n",
    "test_images, test_img_labels = load_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_predictions(test_data):\n",
    "    predictions_classes = []\n",
    "    for image in test_data:\n",
    "        image = image.reshape(1,64,64,3)\n",
    "        pred = model.predict_classes(image)\n",
    "        predictions_classes.append(pred[0])\n",
    "    return predictions_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: F | Predicted J\n",
      "Actual: G | Predicted J\n",
      "Actual: L | Predicted B\n",
      "Actual: M | Predicted J\n",
      "Actual: R | Predicted J\n",
      "Actual: S | Predicted J\n",
      "Actual: X | Predicted J\n",
      "Actual: Y | Predicted J\n",
      "Actual: U | Predicted J\n",
      "Actual: T | Predicted J\n",
      "Actual: A | Predicted B\n",
      "Actual: K | Predicted J\n",
      "Actual: J | Predicted J\n",
      "Actual: Z | Predicted B\n",
      "Actual: nothing | Predicted J\n",
      "Actual: Q | Predicted B\n",
      "Actual: P | Predicted J\n",
      "Actual: space | Predicted J\n",
      "Actual: O | Predicted B\n",
      "Actual: N | Predicted J\n",
      "Actual: E | Predicted J\n",
      "Actual: D | Predicted J\n",
      "Actual: H | Predicted J\n",
      "Actual: I | Predicted D\n",
      "Actual: B | Predicted E\n",
      "Actual: C | Predicted B\n",
      "Actual: V | Predicted D\n",
      "Actual: W | Predicted J\n"
     ]
    }
   ],
   "source": [
    "pre = give_predictions(test_images)\n",
    "for i, j in zip(pre, test_img_labels):\n",
    "    print('Actual: %s | Predicted %s' % (data_inverse[j], data_inverse[i]))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78517 samples, validate on 4133 samples\n",
      "Epoch 1/1\n",
      "12992/78517 [===>..........................] - ETA: 10:20 - loss: 2.2314 - acc: 0.4074"
     ]
    }
   ],
   "source": [
    "# for training for long amounts of time\n",
    "def train_model_long():\n",
    "    h = model.fit(X_train, Y_train, epochs = 1, validation_split = 0.05, batch_size=64)\n",
    "    return h\n",
    "\n",
    "h = train_model_long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
